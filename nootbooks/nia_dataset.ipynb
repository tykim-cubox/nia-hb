{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose annotation files\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = Path('/home/aiteam/tykim/nia-3d/indoor')\n",
    "out_path = Path('/home/aiteam/tykim/nia-3d/outdoor')\n",
    "# 156개\n",
    "json_list = list(in_path.glob('*.json')) + list(out_path.glob('*.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joints_name_24 = [\n",
    "        'pelvis', 'left_hip', 'right_hip',      # 2\n",
    "        'spine1', 'left_knee', 'right_knee',    # 5\n",
    "        'spine2', 'left_ankle', 'right_ankle',  # 8\n",
    "        'spine3', 'left_foot', 'right_foot',    # 11\n",
    "        'neck', 'left_collar', 'right_collar',  # 14\n",
    "        'jaw',                                  # 15\n",
    "        'left_shoulder', 'right_shoulder',      # 17\n",
    "        'left_elbow', 'right_elbow',            # 19\n",
    "        'left_wrist', 'right_wrist',            # 21\n",
    "        'left_thumb', 'right_thumb'             # 23\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_nia3d_smpl_jt = [\n",
    "    -1, -1, -1,\n",
    "    -1, 13, 14,\n",
    "    -1, 15, 16,\n",
    "    -1, -1, -1,\n",
    "    -1, -1, -1,\n",
    "    -1,\n",
    "    5, 6,\n",
    "    7, 8,\n",
    "    9, 10,\n",
    "    -1, -1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nia_joint_name = ['pelvis',\n",
    " 'left hip',\n",
    " 'left knee',\n",
    " 'left ankle',\n",
    " 'left bigtoe', # x\n",
    " 'left littletoe',# x\n",
    " 'right hip',\n",
    " 'right_knee',\n",
    " 'right ankle',\n",
    " 'right bigtoe', # x\n",
    " 'right littletoe',# x\n",
    " 'waist',# x\n",
    " 'chest',# x\n",
    " 'neck',\n",
    " 'left shoulder',\n",
    " 'left elbow',\n",
    " 'left wrist',\n",
    " 'left index finger',# x\n",
    " 'left pinky',# x\n",
    " 'right shoulder',\n",
    " 'right elbow',\n",
    " 'right wrist',\n",
    " 'right index finger', # x\n",
    " 'right pinky', # x\n",
    " 'nose', # x\n",
    " 'left eye', # x\n",
    " 'left ear', # x\n",
    " 'right eye',# x\n",
    " 'right ear'] # x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "joints_3d_name = ['pelvis',\n",
    "                  'left hip','left knee', 'left ankle',\n",
    "                  'right hip','right_knee', 'right ankle',\n",
    "                  'neck',\n",
    "                  'left shoulder','left elbow','left wrist',\n",
    "                  'right shoulder','right elbow','right wrist'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "annos = {\"annotations\": []}\n",
    "\n",
    "joints_3d_name = ['pelvis',\n",
    "                  'left hip','left knee', 'left ankle',\n",
    "                  'right hip','right_knee', 'right ankle',\n",
    "                  'neck',\n",
    "                  'left shoulder','left elbow','left wrist',\n",
    "                  'right shoulder','right elbow','right wrist'] # 0-13 torso, nose, head 없음\n",
    "joints_2d_name = ['nose', 'left eye', 'right eye', 'left ear', 'right ear',    # 0-4\n",
    "                   'left shoulder', 'right shoulder',                           # 6\n",
    "                   'left elbow', 'right elbow',                                 # 8\n",
    "                   'left wrist', 'right wrist',                                 # 10\n",
    "                   'left hip', 'right hip',                                     # 12\n",
    "                   'left knee', 'right_knee',                                   # 14\n",
    "                   'left ankle', 'right ankle']                                 # 16\n",
    "\n",
    "for anno_json in json_list:\n",
    "  with open(anno_json) as f:\n",
    "    nia_anno = json.load(f)\n",
    "\n",
    "  if 'meta' in nia_anno:\n",
    "    nia_anno_meta = nia_anno['meta']\n",
    "  else:\n",
    "    nia_anno_meta = nia_anno\n",
    "      \n",
    "  tmp = {}\n",
    "  human_ann = {}\n",
    "  # list of dict를 nested \n",
    "  for anno_dict in nia_anno['objects']:\n",
    "    for k, v in anno_dict.items():\n",
    "      human_ann[k] = v\n",
    "  \n",
    "  newlist = []\n",
    "  for joint in joints_2d_name:\n",
    "    for key_anno in human_ann['annotation.human.keypoint.2d']:\n",
    "      if key_anno['name'] == joint:\n",
    "        newlist.append(key_anno)\n",
    "      \n",
    "      \n",
    "  # remove first and then sort\n",
    "  # newlist = [{key:  val for key, val in human_ann['annotation.human.keypoint.2d'].items() if key is joint} for joint in joints_name]\n",
    "        \n",
    "        \n",
    "  # print(newlist)\n",
    "  kp_list = []\n",
    "  for kp in newlist:\n",
    "    kp_list.append(kp['x'])\n",
    "    kp_list.append(kp['y'])\n",
    "    kp_list.append(int(kp['state']['visible']))\n",
    "      \n",
    "    # print(kp_list)\n",
    "    # sorted(human_ann['annotation.human.keypoint.2d'], key=lambda d: [k in d for k in joints_name], reverse=True)\n",
    "\n",
    "    # sorted(human_ann['annotation.human.keypoint.2d'], key = lambda item: joints_name.index(item['name']) if item['name'] in joints_name)\n",
    "    \n",
    "    # newlist = sorted(human_ann['annotation.human.keypoint.2d'], key=itemgetter('name')) \n",
    "    # newlist = [i for i in newlist if i['name'] in joints_name]\n",
    "    # print('dd : ', newlist)\n",
    "\n",
    "\n",
    "\n",
    "  # #######################\n",
    "  # new_3d_list = []\n",
    "  # for joint in joints_3d_name:\n",
    "  #   for key_anno in human_ann['annotation.human.keypoint.3d']:\n",
    "  #     if key_anno['name'] == joint:\n",
    "  #       new_3d_list.append(key_anno) # list of dict\n",
    "\n",
    "  \n",
    "  # kp_3d_list = []\n",
    "  # visibility_3d = []\n",
    "  # for kp in new_3d_list:\n",
    "  #   kp_3d_list.append(kp['x'])\n",
    "  #   kp_3d_list.append(kp['y'])\n",
    "  #   kp_3d_list.append(kp['z'])\n",
    "\n",
    "  #   if int(kp['state']['visible']):\n",
    "  #     visibility_3d.append(np.ones((3)))\n",
    "\n",
    "  # visibility_3d = np.stack(visibility_3d, axis=0)\n",
    "\n",
    "  # ##########################\n",
    "  random_3d_keys = np.random.randn(14,3)\n",
    "  random_3d_visible = np.ones((14,3))\n",
    "  kp_3d_list = []\n",
    "  for key in random_3d_keys:\n",
    "    kp_3d_list.append(key[0])\n",
    "    kp_3d_list.append(key[1])\n",
    "    kp_3d_list.append(key[2])\n",
    "  visibility_3d = random_3d_visible.tolist()\n",
    "\n",
    "\n",
    "  np.random.randn(24,3)\n",
    "  \n",
    "  bbox_list = []\n",
    "  for k,v in human_ann['annotation.human.bbox.2d'].items():\n",
    "    bbox_list.append(v)\n",
    "    \n",
    "  # tmp['bbox'] = human_ann['annotation.human.bbox.2d'] \n",
    "  tmp['keypoints'] = kp_list\n",
    "  tmp['keypoints_3d'] = kp_3d_list\n",
    "  tmp['keypoints_3d_visible'] = visibility_3d\n",
    "  tmp['smpl_joints'] = np.random.randn(24,3).tolist()\n",
    "  tmp['bbox'] = bbox_list\n",
    "\n",
    "  tmp['image'] = nia_anno[\"info.image.id\"]\n",
    "  name, ext = nia_anno[\"info.image.id\"].split('.')\n",
    "  tmp['image'] = name + '.' +  ext.lower()\n",
    "  tmp['width'] = nia_anno_meta[\"info.image.width\"] # weight\n",
    "  tmp['height'] = nia_anno_meta[\"info.image.height\"] # height\n",
    "\n",
    "  focal_length_str = nia_anno_meta[\"info.camera.focal_length\"]\n",
    "  focal_length_list = focal_length_str.strip('\"').strip('[').strip(']').split()\n",
    "  focal_length = [float(f) for f in focal_length_list]\n",
    "  tmp['f'] = focal_length  # f\n",
    "\n",
    "\n",
    "  principal_point_str = nia_anno_meta[\"info.camera.principal_point\"]\n",
    "  principal_point_str_list = principal_point_str.strip('\"').strip('[').strip(']').split()\n",
    "  principal_point_str = [float(c) for c in principal_point_str_list]\n",
    "  tmp['c'] = principal_point_str # c\n",
    "  annos['annotations'].append(tmp)\n",
    "    # for human_anno in nia_anno['objects']:\n",
    "    #   if 'annotation.human.bbox.2d' in human_anno:\n",
    "    #     tmp['bbox'] = human_anno['annotation.human.bbox.2d'] # bbox\n",
    "    #   if 'annotation.human.keypoint.2d' in human_anno:\n",
    "    #     for joint in joints_name:\n",
    "    #       if kp['name'] == joint:\n",
    "            \n",
    "    #     for kp in human_anno['annotation.human.keypoint.2d']:\n",
    "    #       # 순서 대로 가져오기\n",
    "    #       if kp['name']\n",
    "    #       tmp['keypoints'] = human_anno['annotation.human.keypoint.2d'] # keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/aiteam/tykim/nia-3d/HybrIK/data/nia/annotations/nia_ann2.json\", \"w\") as outfile:\n",
    "    json.dump(annos, outfile)\n",
    "\n",
    "# Check\n",
    "# with open('/home/aiteam/tykim/nia-3d/HybrIK/data/nia/annotations/nia_ann.json') as f:\n",
    "#   data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/aiteam/tykim/nia-3d/HybrIK/data/nia/annotations/nia_ann2.json') as f:\n",
    "  data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hybrik.utils.bbox import bbox_clip_xyxy, bbox_xywh_to_xyxy\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/aiteam/tykim/nia-3d/HybrIK/data/nia/annotations/nia_ann.json', 'r') as fid:\n",
    "    database = json.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'str'>\n",
      "4000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1458666/969732930.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann_annotation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'width'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   xmin, ymin, xmax, ymax = bbox_clip_xyxy(\n\u001b[0;32m----> 9\u001b[0;31m                 bbox_xywh_to_xyxy(ann_annotation['bbox']), ann_annotation['width'], ann_annotation['height'])\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tykim/HybrIK/hybrik/utils/bbox.py\u001b[0m in \u001b[0;36mbbox_clip_xyxy\u001b[0;34m(xyxy, width, height)\u001b[0m\n\u001b[1;32m    132\u001b[0m             raise IndexError(\n\u001b[1;32m    133\u001b[0m                 \"Bounding boxes must have 4 elements, given {}\".format(len(xyxy)))\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxyxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxyxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxyxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "for ann_annotation in database['annotations']:\n",
    "\n",
    "  print(type(ann_annotation['bbox']))\n",
    "  # print(type(ann_annotation['bbox'][0]))\n",
    "  t=  bbox_xywh_to_xyxy(ann_annotation['bbox'])\n",
    "  print(type(ann_annotation['width']))\n",
    "  print(ann_annotation['width'])\n",
    "  xmin, ymin, xmax, ymax = bbox_clip_xyxy(\n",
    "                bbox_xywh_to_xyxy(ann_annotation['bbox']), float(ann_annotation['width'], ann_annotation['height'])\n",
    "  print(t)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_joints = 17\n",
    "labels = []\n",
    "items  = []\n",
    "root = '/home/aiteam/tykim/nia-3d/HybrIK/data/nia/imgs'\n",
    "for ann_annotation in database['annotations']:\n",
    "    label = []\n",
    "    image = ann_annotation['image']\n",
    "    width, height = float(ann_annotation['width']), float(ann_annotation['height'])\n",
    "    \n",
    "    # bbox = np.asarray(ann_annotation['bbox'][0], dtype=np.float32)\n",
    "    xmin, ymin, xmax, ymax = bbox_clip_xyxy(\n",
    "                bbox_xywh_to_xyxy(ann_annotation['bbox']), width, height)\n",
    "\n",
    "\n",
    "    # 이걸 annoatation을 저장할 때 넣어야 함\n",
    "    if xmax <= xmin or ymax <= ymin:\n",
    "        continue\n",
    "\n",
    "    \n",
    "    # joints 3d: (num_joints, 3, 2); 3 is for x, y, z; 2 is for position, visibility\n",
    "    joints_3d = np.zeros((num_joints, 3, 2), dtype=np.float32)\n",
    "    for i in range(num_joints):\n",
    "        joints_3d[i, 0, 0] = ann_annotation['keypoints'][i * 3 + 0]\n",
    "        joints_3d[i, 1, 0] = ann_annotation['keypoints'][i * 3 + 1]\n",
    "        # joints_3d[i, 2, 0] = 0\n",
    "        visible = min(1, ann_annotation['keypoints'][i * 3 + 2])\n",
    "        joints_3d[i, :2, 1] = visible\n",
    "        \n",
    "    if np.sum(joints_3d[:, 0, 1]) < 1:\n",
    "        # no visible keypoint\n",
    "        continue\n",
    "    # 2D 데이터셋에선 필요없음    \n",
    "    # f = np.array(ann_annotations['f'], dtype=np.float32)\n",
    "    # c = np.array(ann_annotations['c'], dtype=np.float32)\n",
    "    \n",
    "    label.append({'bbox' : (xmin, ymin, xmax, ymax),\n",
    "                  'width': width,\n",
    "                  'height': height,\n",
    "                  'joints_3d': joints_3d,\n",
    "                  'keypoints': ann_annotation['keypoints']})\n",
    "    \n",
    "    abs_path = os.path.join(root, image)\n",
    "    items.append(abs_path)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/home/aiteam/tykim/HybrIK/data/coco/annotations/person_keypoints_train2017.json') as f:\n",
    "  data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['info', 'licenses', 'images', 'annotations', 'categories'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['segmentation', 'num_keypoints', 'area', 'iscrowd', 'keypoints', 'image_id', 'bbox', 'category_id', 'id'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['annotations'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import pickle as pk\n",
    "\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import torch.utils.data as data\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "from hybrik.utils.bbox import bbox_clip_xyxy, bbox_xywh_to_xyxy\n",
    "from hybrik.utils.presets import SimpleTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NIA(data.Dataset):\n",
    "    CLASSES = ['person']\n",
    "    num_joints = 17\n",
    "    EVAL_JOINTS = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
    "    joints_name = ('nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear',    # 4\n",
    "                    'left_shoulder', 'right_shoulder',                           # 6\n",
    "                    'left_elbow', 'right_elbow',                                 # 8\n",
    "                    'left_wrist', 'right_wrist',                                 # 10\n",
    "                    'left_hip', 'right_hip',                                     # 12\n",
    "                    'left_knee', 'right_knee',                                   # 14\n",
    "                    'left_ankle', 'right_ankle')                                 # 16\n",
    "    def __init__(self,\n",
    "                    cfg,\n",
    "                    ann_file,\n",
    "                    root='./data/nia',\n",
    "                    img_folder = 'imgs',\n",
    "                    train=True,\n",
    "                    skip_empty=True,\n",
    "                    dpg=False,\n",
    "                    lazy_import=False):\n",
    "        self._cfg = cfg\n",
    "        self._ann_file = os.path.join(root, 'annotations', ann_file)\n",
    "        self._lazy_import = lazy_import\n",
    "        self._root = root\n",
    "        self._img_folder = img_folder\n",
    "        self._skip_empty = skip_empty\n",
    "        self._train = train\n",
    "        self._dpg = dpg\n",
    "\n",
    "        self._scale_factor = cfg.DATASET.SCALE_FACTOR\n",
    "        self._color_factor = cfg.DATASET.COLOR_FACTOR\n",
    "        self._rot = cfg.DATASET.ROT_FACTOR\n",
    "        self._input_size = cfg.MODEL.IMAGE_SIZE\n",
    "        self._output_size = cfg.MODEL.HEATMAP_SIZE\n",
    "\n",
    "        self._occlusion = cfg.DATASET.OCCLUSION\n",
    "\n",
    "        self._crop = cfg.MODEL.EXTRA.CROP\n",
    "        self._sigma = cfg.MODEL.EXTRA.SIGMA\n",
    "\n",
    "        self._check_centers = False\n",
    "\n",
    "        self.num_class = len(self.CLASSES)\n",
    "\n",
    "        self.num_joints_half_body = cfg.DATASET.NUM_JOINTS_HALF_BODY\n",
    "        self.prob_half_body = cfg.DATASET.PROB_HALF_BODY\n",
    "\n",
    "        self.augment = cfg.MODEL.EXTRA.AUGMENT\n",
    "\n",
    "        self._loss_type = cfg.LOSS['TYPE']\n",
    "\n",
    "        self.upper_body_ids = (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n",
    "        self.lower_body_ids = (11, 12, 13, 14, 15, 16)\n",
    "\n",
    "\n",
    "        if cfg.MODEL.EXTRA.PRESET == 'simple_smpl_3d':\n",
    "                self.transformation = SimpleTransform(\n",
    "                    self, scale_factor=self._scale_factor,\n",
    "                    color_factor=self._color_factor,\n",
    "                    occlusion=self._occlusion,\n",
    "                    input_size=self._input_size,\n",
    "                    output_size=self._output_size,\n",
    "                    rot=self._rot, sigma=self._sigma,\n",
    "                    train=self._train, add_dpg=self._dpg,\n",
    "                    loss_type=self._loss_type, dict_output=True)\n",
    "\n",
    "        self._items, self._labels = self._load_jsons()\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get image id\n",
    "        img_path = self._items[idx]\n",
    "        img_id = os.path.splitext(os.path.basename(img_path))[0]\n",
    "\n",
    "        # load ground truth, including bbox, keypoints, image size\n",
    "        label = copy.deepcopy(self._labels[idx])\n",
    "        img = scipy.misc.imread(img_path, mode='RGB')\n",
    "        # transform ground truth into training label and apply data augmentation\n",
    "        target = self.transformation(img, label)\n",
    "\n",
    "        img = target.pop('image')\n",
    "        bbox = target.pop('bbox')\n",
    "        return img, target, img_id, bbox\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._items)\n",
    "    \n",
    "    def _load_jsons(self):\n",
    "        \"\"\"Load all image paths and labels from JSON annotation files into buffer.\"\"\"\n",
    "        labels = []\n",
    "        items  = []\n",
    "        for ann_annotation in database['annotations']:\n",
    "            image = ann_annotation['image']\n",
    "            width, height = float(ann_annotation['width']), float(ann_annotation['height'])\n",
    "            \n",
    "            # bbox = np.asarray(ann_annotation['bbox'][0], dtype=np.float32)\n",
    "            xmin, ymin, xmax, ymax = bbox_clip_xyxy(\n",
    "                        bbox_xywh_to_xyxy(ann_annotation['bbox']), width, height)\n",
    "\n",
    "\n",
    "            if xmax <= xmin or ymax <= ymin:\n",
    "                continue\n",
    "            \n",
    "            # joints 3d: (num_joints, 3, 2); 3 is for x, y, z; 2 is for position, visibility\n",
    "            joints_3d = np.zeros((num_joints, 3, 2), dtype=np.float32)\n",
    "            for i in range(num_joints):\n",
    "                joints_3d[i, 0, 0] = ann_annotation['keypoints'][i * 3 + 0]\n",
    "                joints_3d[i, 1, 0] = ann_annotation['keypoints'][i * 3 + 1]\n",
    "                # joints_3d[i, 2, 0] = 0\n",
    "                visible = min(1, ann_annotation['keypoints'][i * 3 + 2])\n",
    "                joints_3d[i, :2, 1] = visible\n",
    "                \n",
    "            if np.sum(joints_3d[:, 0, 1]) < 1:\n",
    "                # no visible keypoint\n",
    "                continue\n",
    "            # 2D 데이터셋에선 필요없음    \n",
    "            # f = np.array(ann_annotations['f'], dtype=np.float32)\n",
    "            # c = np.array(ann_annotations['c'], dtype=np.float32)\n",
    "            \n",
    "            labels.append({'bbox' : (xmin, ymin, xmax, ymax),\n",
    "                        'width': width,\n",
    "                        'height': height,\n",
    "                        'joints_3d': joints_3d,\n",
    "                        'keypoints': ann_annotation['keypoints']})\n",
    "            \n",
    "            abs_path = os.path.join(self._root, self._img_folder, image)\n",
    "            items.append(abs_path)\n",
    "        return items, labels\n",
    "    \n",
    "    @property\n",
    "    def joint_pairs(self):\n",
    "        \"\"\"Joint pairs which defines the pairs of joint to be swapped\n",
    "        when the image is flipped horizontally.\"\"\"\n",
    "        return [[1, 2], [3, 4], [5, 6], [7, 8],\n",
    "                [9, 10], [11, 12], [13, 14], [15, 16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "\n",
    "def update_config(config_file):\n",
    "    with open(config_file) as f:\n",
    "        config = edict(yaml.load(f, Loader=yaml.FullLoader))\n",
    "        return config\n",
    "\n",
    "cfg = update_config('/home/aiteam/tykim/HybrIK/configs/256x192_adam_lr1e-3-res34_smpl_3d_cam_2x_mix.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "nia_dataset = NIA(cfg, ann_file='/home/aiteam/tykim/nia-3d/HybrIK/data/nia/annotations/nia_ann.json', root='/home/aiteam/tykim/nia-3d/HybrIK/data/nia', img_folder='imgs2',train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiteam/miniconda3/envs/hybrik/lib/python3.7/site-packages/ipykernel_launcher.py:77: DeprecationWarning:     `imread` is deprecated!\n",
      "    `imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "    Use ``imageio.imread`` instead.\n"
     ]
    }
   ],
   "source": [
    "img, target, img_id, bbox = nia_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 502.7144, 1797.4285, 3856.6860, 5151.4004])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': '2d_data',\n",
       " 'target': tensor([-8.8626e-02, -4.1423e-01, -8.3322e-02, -4.4076e-01, -1.0808e-01,\n",
       "         -4.3368e-01, -1.9667e-02, -4.8496e-01,  6.6912e+00,  7.6912e+00,\n",
       "          7.2279e-02, -3.4881e-01, -7.0944e-02, -3.2052e-01,  1.4477e-01,\n",
       "         -1.8614e-01,  6.9923e+00,  9.9846e+00, -2.1684e-04, -1.7729e-01,\n",
       "          6.7143e+00,  1.0541e+01,  2.8074e-02,  1.1901e-02, -6.3872e-02,\n",
       "          2.0742e-02,  2.4538e-02,  2.5768e-01, -2.8508e-02,  2.0463e-01,\n",
       "          2.6306e-02,  4.4157e-01, -5.5214e-03,  3.6554e-01]),\n",
       " 'target_weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "         1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'trans_inv': tensor([[  13.1015,   -0.0000,  502.7144],\n",
       "         [   0.0000,   13.1015, 1797.4285]]),\n",
       " 'intrinsic_param': tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]),\n",
       " 'joint_root': tensor([0., 0., 0.]),\n",
       " 'depth_factor': tensor([2000.])}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiteam/miniconda3/envs/hybrik/lib/python3.7/site-packages/tqdm-4.64.0-py3.7.egg/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from hybrik.datasets.nia3d import NIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nia_dataset = NIA(cfg, ann_file='/home/aiteam/tykim/nia-3d/HybrIK/data/nia/annotations/nia_ann.json', root='/home/aiteam/tykim/nia-3d/HybrIK/data/nia', img_folder='imgs2',train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, target, img_id, bbox = nia_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': '2d_data',\n",
       " 'target': tensor([ 4.7722e-02, -2.2305e-01,  5.8195e-02, -2.3352e-01,  4.4865e-02,\n",
       "         -2.3733e-01, -5.0000e-01, -5.0000e-01,  1.0590e-02, -2.6113e-01,\n",
       "          3.8201e-02, -1.7259e-01, -3.8919e-02, -1.8782e-01, -5.0000e-01,\n",
       "         -5.0000e-01, -7.7956e-02, -1.0023e-01, -5.0000e-01, -5.0000e-01,\n",
       "          1.1677e-04, -9.5467e-02,  3.4392e-02,  1.1169e-02, -1.5117e-02,\n",
       "          6.4083e-03,  1.5350e-02,  1.1019e-01, -1.3213e-02,  1.3875e-01,\n",
       "          2.9731e-03,  1.9683e-01, -1.4165e-02,  2.3777e-01]),\n",
       " 'target_weight': tensor([1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
       "         0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'trans_inv': tensor([[   24.3313,    -0.0000, -1295.1023],\n",
       "         [    0.0000,    24.3313,   360.0122]]),\n",
       " 'intrinsic_param': tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]),\n",
       " 'joint_root': tensor([0., 0., 0.]),\n",
       " 'depth_factor': tensor([2000.])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_att(sample_n): #torval -> 0 if training and 1 if validation dataset\n",
    "    sample = coco_ann['annotations'][sample_n]\n",
    "    img_id = str(sample['image_id'])\n",
    "    k_list = sample['keypoints']\n",
    "    bbox = sample['bbox']\n",
    "    is_crowd = sample['iscrowd']\n",
    "\n",
    "    #the keypoints in each sample are indicated in a list as: x1, y1, v1, x2, y2, v2, x3... and there are \n",
    "    #17 keypoints, so, we need it in a bidimensional array of 17x3\n",
    "\n",
    "    k_array = np.asarray(k_list)\n",
    "    k_array3d = np.reshape(k_array,(N_KEYPOINTS,N_DIM))\n",
    "    keypoints = k_array3d[:,:2]\n",
    "    k_vis = k_array3d[:,2]\n",
    "    \n",
    "    return img_id,bbox,is_crowd,keypoints,k_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "_ann_file = '/home/aiteam/tykim/nia-3d/HybrIK/data/nia/annotations/nia_ann2.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "joints_name_17 = [\n",
    "        'Pelvis',                               # 0\n",
    "        'L_Hip', 'L_Knee', 'L_Ankle',           # 3\n",
    "        'R_Hip', 'R_Knee', 'R_Ankle',           # 6\n",
    "        'Torso', 'Neck',                        # 8\n",
    "        'Nose', 'Head',                         # 10\n",
    "        'L_Shoulder', 'L_Elbow', 'L_Wrist',     # 13\n",
    "        'R_Shoulder', 'R_Elbow', 'R_Wrist',     # 16\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joints_name_17.index('Torso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I_M078_T041-T01-00_T000-T00-00_B00099_R.jpg\n",
      "42\n",
      "[-1.7058226880727385, -1.2084466864480807, 0.5096165723113794, -0.6437120660426229, 0.5627718601028707, 0.6267703767666232, 1.0866949206332164, 0.6441654453227851, 0.025469474669195538, 1.7823148246606362, -1.2430160981199818, 0.9745316718538839, -1.649020414126998, 0.9923082228925614, -0.18309371349184103, -0.05434374449023047, -1.378125500394191, 1.1984672957367062, -0.9209684852480394, 0.788346104957958, -1.7260633236522687, 0.0, 0.0, 0.0, 0.14103966419098043, -0.22501489217366438, 0.17459072733779266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1802236225513358, 1.8226829940627027, 0.20993272160435153, 1.4428951576454963, 1.873594306751139, 0.6136633034388078, -0.5604882526811924, 0.7610432418653048, 0.8764692704206664, -0.11338252706514132, -1.4348538860226483, -0.2385002502329084, 1.1834554093268108, -0.6374888873854869, -1.2122875066996766, 0.536872148251385, -0.32849752374186364, 0.202198260316526]\n"
     ]
    }
   ],
   "source": [
    "with open(_ann_file, 'r') as fid:\n",
    "  database = json.load(fid)\n",
    "\n",
    "\n",
    "for ann in database['annotations']:\n",
    "  image = ann['image']\n",
    "  print(image)\n",
    "\n",
    "  keypoints_3d = ann['keypoints_3d']\n",
    "  print(len(keypoints_3d)) # 14 x 3\n",
    "\n",
    "  for idx in [joints_name_17.index('Torso'), joints_name_17.index('Nose'), joints_name_17.index('Head')]:\n",
    "    keypoints_3d.insert(idx*3, float(0))\n",
    "    keypoints_3d.insert(idx*3+1, float(0))\n",
    "    keypoints_3d.insert(idx*3+2, float(0))\n",
    "\n",
    "  f, c = np.array(ann['cam_param']['f'], dtype=np.float32), np.array(\n",
    "                ann['cam_param']['c'], dtype=np.float32)\n",
    "\n",
    "  \n",
    "  joint_cam_17 = np.array(keypoints_3d).reshape(17, 3)\n",
    "  joint_img_17 = cam2pixel(joint_cam_17, f, c)\n",
    "\n",
    "  ann['keypoints_3d']\n",
    "  break\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = ann['width'], ann['height']\n",
    "\n",
    "  xmin, ymin, xmax, ymax = bbox_clip_xyxy(\n",
    "                      bbox_xywh_to_xyxy(ann['bbox']), width, height)\n",
    "\n",
    "\n",
    "  f, c = np.array(ann['cam_param']['f'], dtype=np.float32), np.array(\n",
    "                  ann['cam_param']['c'], dtype=np.float32)\n",
    "\n",
    "  joint_cam_17 = np.array(ann['h36m_joints']).reshape(17, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(self._ann_file, 'r') as fid:\n",
    "            database = json.load(fid)\n",
    "\n",
    "        for ann in database['annotations']:\n",
    "            image = ann['image']\n",
    "            width, height = float(ann['width']), float(ann['height'])\n",
    "            xmin, ymin, xmax, ymax = bbox_clip_xyxy(bbox_xywh_to_xyxy(ann['bbox']), width, height)\n",
    "\n",
    "            ann['keypoints_3d']\n",
    "\n",
    "            labels.append({'bbox' : (xmin, ymin, xmax, ymax),\n",
    "                            'width': width,\n",
    "                            'height': height,\n",
    "                            'keypoints': ann['keypoints'],\n",
    "                            'keypoints_3d' : ann['keypoints_3d']})\n",
    "            abs_path = os.path.join(self._root, self._img_folder, image)\n",
    "            items.append(abs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('hybrik')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e217b4c5fb9259235ccea530538be9833dd50f812ad2e8bc6672c6e5349c3fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
